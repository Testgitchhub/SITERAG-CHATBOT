{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1iQ1jnT0ULZ1cohYibQ_QFFWO9wbfyNu0",
      "authorship_tag": "ABX9TyPOIrSDKlHZ3ebQ6TtaRMuh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Testgitchhub/SITERAG-CHATBOT/blob/main/SITERAG_CHATBOT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3pyRjd39ouyM"
      },
      "outputs": [],
      "source": [
        "!pip install flask-ngrok flask flask-cors python-docx pdfplumber sentence-transformers faiss-cpu openai werkzeug==2.2.3"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DOC_STORE = {} # doc_id -> { 'chunks': [text], 'meta': [ {start, end, filename}], 'emb_index': faiss_index }\n",
        "# Simple text extractor\n",
        "def extract_text_from_pdf(path_or_bytes):\n",
        "text = []\n",
        "if isinstance(path_or_bytes, (bytes, bytearray)):\n",
        "fp = io.BytesIO(path_or_bytes)\n",
        "with pdfplumber.open(fp) as pdf:\n",
        "for p in pdf.pages:\n",
        "text.append(p.extract_text() or '')\n",
        "else:\n",
        "with pdfplumber.open(path_or_bytes) as pdf:\n",
        "for p in pdf.pages:\n",
        "text.append(p.extract_text() or '')\n",
        "return \"\\n\".join(text)\n",
        "def extract_text_from_docx(path_or_bytes):\n",
        "if isinstance(path_or_bytes, (bytes, bytearray)):\n",
        "fp = io.BytesIO(path_or_bytes)\n",
        "doc = docx.Document(fp)\n",
        "else:\n",
        "doc = docx.Document(path_or_bytes)\n",
        "paragraphs = [p.text for p in doc.paragraphs]\n",
        "return \"\\n\".join(paragraphs)\n",
        "def chunk_text(text, chunk_size=500, overlap=50):\n",
        "words = text.split()\n",
        "chunks = []\n",
        "i = 0\n",
        "while i < len(words):\n",
        "chunk = words[i:i+chunk_size]\n",
        "chunks.append(' '.join(chunk))\n",
        "i += chunk_size - overlap\n",
        "return chunks\n",
        "def build_faiss_index(embs):\n",
        "index = faiss.IndexFlatL2(embs.shape[1])\n",
        "index.add(embs)\n",
        "return index\n",
        "def get_embeddings(texts):\n",
        "embs = embed_model.encode(texts, show_progress_bar=False, convert_to_numpy=True)\n",
        "return embs\n",
        "def call_llm_system(prompt, max_tokens=300, temperature=0.1):\n",
        "# Uses OpenAI ChatCompletion (gpt-3.5-turbo). Replace if you want other models.\n",
        "if not openai.api_key:\n",
        "raise ValueError('OPENAI_API_KEY not set in Colab env')\n",
        "res = openai.ChatCompletion.create(\n",
        "model='gpt-3.5-turbo',\n",
        "messages=[\n",
        "{\"role\": \"system\", \"content\": \"You are a helpful assistant that answers questions based only on the provided context. If the answer is not in the context, say you don't know.\"},\n",
        "{\"role\": \"user\", \"content\": prompt},\n",
        "],\n",
        "temperature=temperature,\n",
        "max_tokens=max_tokens,\n",
        ")\n",
        "return res['choices'][0]['message']['content'].strip()"
      ],
      "metadata": {
        "id": "GuUNWcVFpC66"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from flask_ngrok import run_with_ngrok\n",
        "data = f.read()\n",
        "lower = filename.lower()\n",
        "if lower.endswith('.pdf'):\n",
        "text = extract_text_from_pdf(data)\n",
        "elif lower.endswith('.docx'):\n",
        "text = extract_text_from_docx(data)\n",
        "else:\n",
        "try:\n",
        "text = data.decode('utf-8')\n",
        "except Exception:\n",
        "return jsonify({'error':'unsupported file type'}), 400\n",
        "chunks = chunk_text(text, chunk_size=300, overlap=30)\n",
        "embs = get_embeddings(chunks)\n",
        "index = build_faiss_index(embs)\n",
        "doc_id = str(len(DOC_STORE) + 1)\n",
        "DOC_STORE[doc_id] = {\n",
        "'filename': filename,\n",
        "'chunks': chunks,\n",
        "'embs': embs,\n",
        "'index': index,\n",
        "}\n",
        "return jsonify({'doc_id': doc_id, 'n_chunks': len(chunks)})\n",
        "@app.route('/query', methods=['POST'])\n",
        "def query_doc():\n",
        "data = request.get_json(force=True)\n",
        "doc_id = data.get('doc_id')\n",
        "question = data.get('question')\n",
        "top_k = int(data.get('top_k', 4))\n",
        "if not doc_id or not question:\n",
        "return jsonify({'error':'doc_id and question required'}), 400\n",
        "if doc_id not in DOC_STORE:\n",
        "return jsonify({'error':'doc_id not found'}), 404\n",
        "store = DOC_STORE[doc_id]\n",
        "q_emb = get_embeddings([question])\n",
        "D, I = store['index'].search(q_emb, top_k)\n",
        "retrieved = [store['chunks'][int(i)] for i in I[0] if i != -1]\n",
        "# Build prompt\n",
        "context = \"\\n\\n---\\n\\n\".join(retrieved)\n",
        "prompt = f\"Context:\\n{context}\\n\\nQuestion: {question}\\n\\nAnswer concisely and cite the chunk if needed.\"\n",
        "try:\n",
        "answer = call_llm_system(prompt)\n",
        "except Exception as e:\n",
        "return jsonify({'error': str(e)}), 500\n",
        "return jsonify({'answer': answer, 'retrieved_chunks': retrieved})\n",
        "# Start Flask\n",
        "print('Starting Flask server with ngrok...')\n",
        "app.run()"
      ],
      "metadata": {
        "id": "3MyyC2jvpVuL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Create folder\n",
        "os.makedirs(\"chrome_extension\", exist_ok=True)\n",
        "\n",
        "# Create files\n",
        "files = {\n",
        "    \"chrome_extension/manifest.json\": \"\"\"\n",
        "{\n",
        "  \"manifest_version\": 3,\n",
        "  \"name\": \"RAG Document Q&A\",\n",
        "  \"version\": \"1.0\",\n",
        "  \"description\": \"Ask questions about uploaded documents using RAG.\",\n",
        "  \"permissions\": [\"activeTab\", \"storage\"],\n",
        "  \"action\": {\n",
        "    \"default_popup\": \"popup.html\"\n",
        "  }\n",
        "}\n",
        "\"\"\",\n",
        "\n",
        "    \"chrome_extension/popup.html\": \"\"\"\n",
        "<!DOCTYPE html>\n",
        "<html>\n",
        "<head>\n",
        "  <title>RAG Q&A</title>\n",
        "  <link rel=\"stylesheet\" href=\"styles.css\" />\n",
        "</head>\n",
        "<body>\n",
        "  <h2>Ask from Document</h2>\n",
        "  <input type=\"file\" id=\"fileInput\" />\n",
        "  <input type=\"text\" id=\"questionInput\" placeholder=\"Ask your question...\" />\n",
        "  <button id=\"askButton\">Ask</button>\n",
        "  <div id=\"answer\"></div>\n",
        "  <script src=\"popup.js\"></script>\n",
        "</body>\n",
        "</html>\n",
        "\"\"\",\n",
        "\n",
        "    \"chrome_extension/popup.js\": \"\"\"\n",
        "document.getElementById('askButton').addEventListener('click', async () => {\n",
        "  const question = document.getElementById('questionInput').value;\n",
        "  const file = document.getElementById('fileInput').files[0];\n",
        "\n",
        "  if (!file || !question) {\n",
        "    alert(\"Please upload a document and enter a question!\");\n",
        "    return;\n",
        "  }\n",
        "\n",
        "  const formData = new FormData();\n",
        "  formData.append(\"file\", file);\n",
        "\n",
        "  const backendURL = \"https://YOUR_NGROK_URL/upload\"; // Replace with your actual backend URL\n",
        "  await fetch(backendURL, { method: \"POST\", body: formData });\n",
        "\n",
        "  const queryRes = await fetch(\"https://YOUR_NGROK_URL/query\", {\n",
        "    method: \"POST\",\n",
        "    headers: { \"Content-Type\": \"application/json\" },\n",
        "    body: JSON.stringify({ question })\n",
        "  });\n",
        "\n",
        "  const data = await queryRes.json();\n",
        "  document.getElementById('answer').textContent = data.answer;\n",
        "});\n",
        "\"\"\",\n",
        "\n",
        "    \"chrome_extension/styles.css\": \"\"\"\n",
        "body {\n",
        "  font-family: Arial, sans-serif;\n",
        "  width: 300px;\n",
        "  padding: 10px;\n",
        "}\n",
        "h2 {\n",
        "  text-align: center;\n",
        "}\n",
        "input, button {\n",
        "  width: 100%;\n",
        "  margin-top: 5px;\n",
        "  padding: 6px;\n",
        "}\n",
        "#answer {\n",
        "  margin-top: 10px;\n",
        "  padding: 8px;\n",
        "  background: #f5f5f5;\n",
        "  border-radius: 8px;\n",
        "}\n",
        "\"\"\"\n",
        "}\n",
        "\n",
        "# Write files\n",
        "for path, content in files.items():\n",
        "    with open(path, \"w\") as f:\n",
        "        f.write(content.strip())\n",
        "\n",
        "print(\"âœ… Chrome Extension files created successfully!\")\n"
      ],
      "metadata": {
        "id": "HTdWezrBsM9B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls chrome_extension"
      ],
      "metadata": {
        "id": "_cIUTTwesR-b"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}